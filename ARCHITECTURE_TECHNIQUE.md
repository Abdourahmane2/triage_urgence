#  Architecture Technique - SystÃ¨me de Triage IA

<div align="center">

![Architecture](https://img.shields.io/badge/Documentation-Technique-red?style=for-the-badge)
![Niveau](https://img.shields.io/badge/Niveau-AvancÃ©-orange?style=for-the-badge)

**Documentation technique complÃ¨te du systÃ¨me**

</div>

---

##  Table des MatiÃ¨res

1. [ Vue d'Ensemble](#-vue-densemble)
2. [ Architecture Globale](#ï¸-architecture-globale)
3. [ Structure du Projet](#-structure-du-projet)
4. [ Composants Principaux](#-composants-principaux)
5. [ Flux de DonnÃ©es](#-flux-de-donnÃ©es)
6. [ Stockage & Persistance](#ï¸-stockage--persistance)
7. [ Intelligence Artificielle](#-intelligence-artificielle)
8. [ Monitoring & MÃ©triques](#-monitoring--mÃ©triques)
9. [ SÃ©curitÃ©](#-sÃ©curitÃ©)
10. [ Performance](#-performance)

---

##  Vue d'Ensemble

### Philosophie du SystÃ¨me

Le systÃ¨me suit une **architecture en couches** avec sÃ©paration claire des responsabilitÃ©s :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PRÃ‰SENTATION (UI)               â”‚  â† Streamlit
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      ORCHESTRATION (Workflows)          â”‚  â† Business Logic
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   AGENTS (IA Conversationnelle)         â”‚  â† Intelligent Agents
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      SERVICES (ML, RAG, LLM)            â”‚  â† AI Services
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     MODÃˆLES (Data & Domain)             â”‚  â† Data Models
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Principes de Design

1. **ModularitÃ©** : Composants indÃ©pendants et rÃ©utilisables
2. **ExtensibilitÃ©** : Facile d'ajouter de nouvelles features
3. **MaintenabilitÃ©** : Code clair et documentÃ©
4. **Performance** : Optimisations ciblÃ©es
5. **Robustesse** : Gestion d'erreurs complÃ¨te

---

##  Architecture Globale

### Diagramme Complet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        UTILISATEUR                             â”‚
â”‚                     (Navigateur Web)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STREAMLIT WEB APP                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Home   â”‚  â”‚   Chat   â”‚  â”‚ Generate â”‚  â”‚ Monitor  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       WORKFLOWS                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  InteractiveWorkflow    â”‚  â”‚  SimulationWorkflow     â”‚   â”‚
â”‚  â”‚  (Chat Interactif)      â”‚  â”‚  (GÃ©nÃ©ration)           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AGENTS     â”‚      â”‚   SERVICES   â”‚      â”‚   STORAGE    â”‚
â”‚              â”‚      â”‚              â”‚      â”‚              â”‚
â”‚ â€¢ Nurse      â”‚      â”‚ â€¢ LLM        â”‚      â”‚ â€¢ ChromaDB   â”‚
â”‚ â€¢ Patient    â”‚      â”‚ â€¢ ML         â”‚      â”‚ â€¢ JSON       â”‚
â”‚ â€¢ Analyzer   â”‚      â”‚ â€¢ RAG        â”‚      â”‚ â€¢ Pickle     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EXTERNAL SERVICES                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Mistral AI  â”‚  â”‚ Embeddings   â”‚  â”‚  Monitoring  â”‚       â”‚
â”‚  â”‚  (API)       â”‚  â”‚ (HuggingFace)â”‚  â”‚  (Local)     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

##  Structure du Projet

### Arborescence DÃ©taillÃ©e

```
triage-urgence/
â”‚
â”œâ”€â”€ ğŸ“ app/                          # Interface Streamlit
â”‚   â”œâ”€â”€ Home.py                      # Page d'accueil
â”‚   â”œâ”€â”€ styles.css                   # CSS global
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ pages/                    # Pages Streamlit
â”‚   â”‚   â”œâ”€â”€ Chat_interactif.py       # Module chat
â”‚   â”‚   â”œâ”€â”€ Generation.py            # GÃ©nÃ©ration datasets
â”‚   â”‚   â””â”€â”€ Monitoring.py            # Dashboard analytics
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ data/                     # DonnÃ©es UI
â”‚       â”œâ”€â”€ ğŸ“ monitoring/           # Logs monitoring
â”‚       â”‚   â”œâ”€â”€ api_calls.json
â”‚       â”‚   â”œâ”€â”€ latencies.json
â”‚       â”‚   â””â”€â”€ predictions.json
â”‚       â”‚
â”‚       â””â”€â”€ ğŸ“ vector_db/            # Base ChromaDB locale
â”‚
â”œâ”€â”€ ğŸ“ src/                          # Code source mÃ©tier
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ agents/                   # Agents intelligents
â”‚   â”‚   â”œâ”€â”€ base_agent.py            # Classe abstraite
â”‚   â”‚   â”œâ”€â”€ nurse_agent.py           # Agent infirmier
â”‚   â”‚   â”œâ”€â”€ patient_simulator.py    # Simulateur patient
â”‚   â”‚   â”œâ”€â”€ patient_generator.py    # GÃ©nÃ©rateur profils
â”‚   â”‚   â””â”€â”€ conversation_analyzer.py # Analyseur dialogue
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ llm/                      # LLM Providers
â”‚   â”‚   â”œâ”€â”€ base_llm.py              # Interface LLM
â”‚   â”‚   â”œâ”€â”€ llm_factory.py           # Factory pattern
â”‚   â”‚   â””â”€â”€ mistral_provider.py     # Provider Mistral
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ rag/                      # RAG System
â”‚   â”‚   â”œâ”€â”€ chatbot.py               # Chatbot principal
â”‚   â”‚   â”œâ”€â”€ predictor.py             # ML + RAG prÃ©diction
â”‚   â”‚   â”œâ”€â”€ document_loader.py       # Chargement docs
â”‚   â”‚   â”œâ”€â”€ embeddings.py            # Sentence transformers
â”‚   â”‚   â”œâ”€â”€ vector_store.py          # ChromaDB wrapper
â”‚   â”‚   â””â”€â”€ retriever.py             # Retrieval logic
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ models/                   # ModÃ¨les de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ conversation.py          # Messages & historique
â”‚   â”‚   â”œâ”€â”€ patient.py               # Patient & constantes
â”‚   â”‚   â”œâ”€â”€ triage.py                # RÃ©sultat triage
â”‚   â”‚   â””â”€â”€ random_forest_simple.pkl # ModÃ¨le ML persistÃ©
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ workflows/                # Orchestration
â”‚   â”‚   â”œâ”€â”€ interactive_workflow.py  # Workflow chat
â”‚   â”‚   â””â”€â”€ simulation_workflow.py  # Workflow gÃ©nÃ©ration
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ monitoring/               # MÃ©triques & logs
â”‚   â”‚   â”œâ”€â”€ metrics_tracker.py       # Tracking metrics
â”‚   â”‚   â””â”€â”€ cost_calculator.py      # Calcul coÃ»ts API
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ utils/                    # Utilitaires
â”‚       â”œâ”€â”€ logger.py                # Logging config
â”‚       â””â”€â”€ validators.py            # Validations
â”‚
â”œâ”€â”€ ğŸ“ data/                         # DonnÃ©es & ressources
â”‚   â”œâ”€â”€ ğŸ“ rag_document/             # Docs pour RAG
â”‚   â”‚   â”œâ”€â”€ protocoles_action.md
â”‚   â”‚   â”œâ”€â”€ criteres_classification.md
â”‚   â”‚   â”œâ”€â”€ arbre_questions.md
â”‚   â”‚   â”œâ”€â”€ signes_alerte.md
â”‚   â”‚   â””â”€â”€ cas_exemples.md
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ vector_db/                # Base vectorielle
â”‚       â””â”€â”€ chroma.sqlite3
â”‚
â”œâ”€â”€ ğŸ“ config/                       # Configuration
â”‚   â”œâ”€â”€ settings.py                  # ParamÃ¨tres globaux
â”‚   â””â”€â”€ prompts.py                   # Prompts LLM
â”‚
â”œâ”€â”€ ğŸ“ tests/                        # Tests unitaires
â”‚   â”œâ”€â”€ test_chatbot.py
â”‚   â”œâ”€â”€ test_ml.py
â”‚   â””â”€â”€ test_rag.py
â”‚
â”œâ”€â”€ .env                             # Variables d'environnement
â”œâ”€â”€ .env.example                     # Template .env
â”œâ”€â”€ requirements.txt                 # DÃ©pendances Python
â”œâ”€â”€ README.md                        # Documentation principale
â””â”€â”€ LICENSE                          # Licence MIT
```

---

## ğŸ”§ Composants Principaux

### 1. Chatbot (src/rag/chatbot.py)

**ResponsabilitÃ© :** Orchestrer le dialogue de triage

**Classe Principale :**
```python
class TriageChatbotAPI:
    """Chatbot ultra robuste pour tous utilisateurs."""
    
    def __init__(self, api_key, retriever):
        # Initialisation Mistral + RAG
        
    def chat(self, user_message: str) -> str:
        # Logique principale
        # 1. Extraction infos
        # 2. DÃ©terminer Ã©tape
        # 3. GÃ©nÃ©rer rÃ©ponse
        
    def _extract_everything(self, msg: str):
        # Extraction agressive multi-formats
        
    def is_ready_for_prediction(self) -> bool:
        # VÃ©rifier complÃ©tude donnÃ©es
```

**Features ClÃ©s :**
-  Extraction temps rÃ©el (5 constantes + identitÃ©)
-  Validation automatique des valeurs
-  Adaptation niveau utilisateur
-  Gestion "je ne sais pas"
-  Questions progressivement simplifiÃ©es

---

### 2. ML Predictor (src/rag/predictor.py)

**ResponsabilitÃ© :** PrÃ©dire la gravitÃ© avec ML + RAG

**Classe Principale :**
```python
class MLTriagePredictor:
    """PrÃ©diction Random Forest + enrichissement RAG."""
    
    def __init__(self, model_path, rag_retriever):
        # Charger modÃ¨le + RAG
        
    def predict(self, chatbot_summary: Dict) -> Dict:
        # 1. PrÃ©parer features
        # 2. PrÃ©dire avec RF
        # 3. Enrichir avec RAG
        # 4. GÃ©nÃ©rer justification
        # 5. Retourner rÃ©sultat complet
        
    def _red_flags(self, vitals, symptoms) -> List[str]:
        # DÃ©tection drapeaux rouges
```

**Pipeline de PrÃ©diction :**
```
Input: RÃ©sumÃ© chatbot
  â†“
1. Extraction features (8 dimensions)
  â†“
2. Normalisation valeurs
  â†“
3. Random Forest predict
  â†“
4. Calcul probabilitÃ©s
  â†“
5. DÃ©tection red flags
  â†“
6. RAG retrieval (contexte mÃ©dical)
  â†“
7. GÃ©nÃ©ration justification
  â†“
Output: RÃ©sultat complet
```

---

### 3. Random Forest (src/models/random_forest_simple.pkl)

**Architecture ML :**

```python
RandomForestClassifier(
    n_estimators=100,      # 100 arbres
    max_depth=20,          # Profondeur max
    min_samples_split=5,   # Split minimum
    min_samples_leaf=2,    # Leaf minimum
    random_state=42        # ReproductibilitÃ©
)
```

**Features (8 dimensions) :**

| # | Feature | Type | Plage | Normalisation |
|---|---------|------|-------|---------------|
| 1 | FC | int | 30-250 | (x-70)/30 |
| 2 | FR | int | 5-60 | (x-16)/5 |
| 3 | SpO2 | int | 50-100 | (x-95)/5 |
| 4 | TA_sys | int | 50-250 | (x-120)/20 |
| 5 | TA_dia | int | 30-150 | (x-80)/10 |
| 6 | Temp | float | 35-42 | (x-37)/2 |
| 7 | Age | int | 0-120 | (x-50)/25 |
| 8 | Sexe | binary | 0/1 | One-hot |

**Classes (4) :**
- 0 â†’ GRIS
- 1 â†’ VERT  
- 2 â†’ JAUNE
- 3 â†’ ROUGE

---

### 4. RAG System (src/rag/)

**Architecture RAG :**

```
Documents Markdown
       â†“
   Chunking (800 chars, overlap 150)
       â†“
   Embeddings (MiniLM-L12-v2, 384 dims)
       â†“
   ChromaDB (persistance)
       â†“
   Retrieval (similaritÃ© cosinus, top-3)
       â†“
   Context enrichment
```

**Composants :**

1. **DocumentLoader** : Charge et dÃ©coupe docs
2. **EmbeddingProvider** : GÃ©nÃ¨re embeddings
3. **VectorStore** : Interface ChromaDB
4. **RAGRetriever** : RÃ©cupÃ¨re contexte

**Documents IndexÃ©s :**
- `protocoles_action.md` (500 chunks)
- `criteres_classification.md` (300 chunks)
- `arbre_questions.md` (400 chunks)
- `signes_alerte.md` (200 chunks)
- `cas_exemples.md` (600 chunks)

**Total :** ~2000 chunks, ~1.6M tokens

---

### 5. Monitoring (src/monitoring/)

**MÃ©triques TrackÃ©es :**

```python
class MetricsTracker:
    """Singleton tracking toutes les mÃ©triques."""
    
    def track_api_call(self, service, model, tokens, latency):
        # Log appel API
        
    def track_latency(self, component, operation, duration):
        # Log latence
        
    def track_prediction(self, severity, age, sex, confidence):
        # Log prÃ©diction
```

**Stockage :**
```json
// app/data/monitoring/api_calls.json
[
  {
    "timestamp": "2026-02-02T10:30:00",
    "service": "mistral",
    "model": "mistral-large-latest",
    "tokens_input": 450,
    "tokens_output": 120,
    "cost": 0.0023,
    "latency": 1.2
  }
]
```

---

##  Flux de DonnÃ©es

### Workflow Chat Interactif

```
1. User clique "DÃ©marrer"
        â†“
2. Chatbot.start() â†’ Message initial
        â†“
3. User tape rÃ©ponse
        â†“
4. Chatbot.chat(msg)
   â”œâ”€â†’ _extract_everything(msg)
   â”‚   â”œâ”€â†’ _extract_prenom()
   â”‚   â”œâ”€â†’ _extract_age()
   â”‚   â”œâ”€â†’ _extract_sexe()
   â”‚   â”œâ”€â†’ _extract_symptoms()
   â”‚   â””â”€â†’ _extract_constantes()
   â”‚
   â”œâ”€â†’ _smart_next_step()
   â”‚   â””â”€â†’ DÃ©termine Ã©tape suivante
   â”‚
   â””â”€â†’ _smart_question(step)
       â””â”€â†’ GÃ©nÃ¨re question adaptÃ©e
        â†“
5. RÃ©pÃ©ter 3-4 jusqu'Ã  complÃ©tude
        â†“
6. User clique "PrÃ©dire"
        â†“
7. Chatbot.get_summary()
        â†“
8. MLTriagePredictor.predict(summary)
   â”œâ”€â†’ _prep_features()
   â”œâ”€â†’ model.predict()
   â”œâ”€â†’ _red_flags()
   â”œâ”€â†’ _rag_enrich()
   â””â”€â†’ _justify()
        â†“
9. Affichage rÃ©sultat
        â†“
10. (Optionnel) Export rapport
```

### Workflow GÃ©nÃ©ration

```
1. User entre pathologie (ou vide)
        â†“
2. SimulationWorkflow.run_simulation(pathology)
        â†“
3. PatientGenerator.generate_from_description(pathology)
   â”œâ”€â†’ LLM gÃ©nÃ¨re profil patient
   â”‚   â”œâ”€â†’ IdentitÃ© (nom, Ã¢ge, sexe)
   â”‚   â”œâ”€â†’ SymptÃ´mes cohÃ©rents
   â”‚   â””â”€â†’ Constantes adaptÃ©es
   â”‚
   â””â”€â†’ Patient object crÃ©Ã©
        â†“
4. PatientSimulator.get_initial_complaint()
   â””â”€â†’ Patient exprime plainte
        â†“
5. NurseAgent.generate_question()
   â””â”€â†’ Infirmier pose questions
        â†“
6. PatientSimulator.respond(question)
   â””â”€â†’ Patient rÃ©pond
        â†“
7. RÃ©pÃ©ter 5-6 (max_turns fois)
        â†“
8. ConversationAnalyzer.extract_patient_info()
   â””â”€â†’ Extraction donnÃ©es conversation
        â†“
9. Export format ML
```

---

##  Stockage & Persistance

### Bases de DonnÃ©es

#### **ChromaDB (Vectorielle)**

**Localisation :** `data/vector_db/chroma.sqlite3`

**Structure :**
```
Collection: triage_medical
â”œâ”€ Documents: ~2000 chunks
â”œâ”€ Embeddings: 384 dimensions (float32)
â”œâ”€ Metadata: {source, title, section, chunk_id}
â””â”€ Index: HNSW (Hierarchical Navigable Small World)
```

**Configuration :**
```python
Settings(
    anonymized_telemetry=False,
    allow_reset=True,
    persist_directory="data/vector_db"
)
```

---

#### **Monitoring (JSON)**

**Localisation :** `app/data/monitoring/*.json`

**Fichiers :**

1. **api_calls.json**
```json
{
  "calls": [
    {
      "timestamp": "ISO-8601",
      "service": "mistral|embeddings",
      "model": "model-name",
      "tokens_input": int,
      "tokens_output": int,
      "cost": float,
      "latency": float,
      "success": bool
    }
  ]
}
```

2. **latencies.json**
```json
{
  "latencies": [
    {
      "timestamp": "ISO-8601",
      "component": "Chatbot|ML|RAG",
      "operation": "message|predict|retrieve",
      "duration": float
    }
  ]
}
```

3. **predictions.json**
```json
{
  "predictions": [
    {
      "timestamp": "ISO-8601",
      "severity": "ROUGE|JAUNE|VERT|GRIS",
      "confidence": float,
      "age": int,
      "sex": "H|F",
      "red_flags": ["..."]
    }
  ]
}
```

---

### ModÃ¨les PersistÃ©s

#### **Random Forest (Pickle)**

**Localisation :** `src/models/random_forest_simple.pkl`

**Format :** scikit-learn pickle (protocol 5)

**Taille :** ~2.5 MB

**Chargement :**
```python
import joblib
model = joblib.load("random_forest_simple.pkl")
```

---

##  Intelligence Artificielle

### Mistral AI (LLM)

**ModÃ¨le :** `mistral-large-latest`

**SpÃ©cifications :**
- **Contexte :** 32k tokens
- **Multilingue :** FranÃ§ais natif
- **Latence :** ~1-2s par requÃªte
- **CoÃ»t :** ~$0.002/message

**Usage dans le SystÃ¨me :**

1. **GÃ©nÃ©ration Questions** (Chatbot)
   ```python
   Temperature: 0.7
   Max Tokens: 100
   System Prompt: "Tu es un infirmier..."
   ```

2. **GÃ©nÃ©ration Patients** (Simulation)
   ```python
   Temperature: 0.8
   Max Tokens: 600
   System Prompt: "GÃ©nÃ¨re un patient rÃ©aliste..."
   ```

3. **Simulation RÃ©ponses** (Patient Simulator)
   ```python
   Temperature: 0.7
   Max Tokens: 150
   System Prompt: "Tu es le patient..."
   ```

---

### Random Forest (ML)

**EntraÃ®nement :**

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(
    features, labels, test_size=0.2, random_state=42
)

# EntraÃ®ner
clf = RandomForestClassifier(
    n_estimators=100,
    max_depth=20,
    min_samples_split=5,
    random_state=42
)
clf.fit(X_train, y_train)

# Ã‰valuer
accuracy = clf.score(X_test, y_test)
```

**MÃ©triques Obtenues :**
```
Accuracy:  87.3%
Precision: 85.6%
Recall:    86.2%
F1-Score:  85.9%
```

**Matrice de Confusion :**
```
              GRIS  VERT  JAUNE  ROUGE
PrÃ©diction
    GRIS      120    15      8      2
    VERT       10   180     12      3
    JAUNE       8    14    190     11
    ROUGE       2     3     10    195
```

---

### RAG (Retrieval Augmented Generation)

**Pipeline Complet :**

```python
# 1. Chargement documents
loader = DocumentLoader()
docs = loader.load_from_directory("data/rag_document/")

# 2. Chunking
chunks = loader.chunk_documents(docs, size=800, overlap=150)

# 3. Embeddings
embedder = EmbeddingProvider("paraphrase-multilingual-MiniLM-L12-v2")
embeddings = embedder.embed_batch([c['text'] for c in chunks])

# 4. Indexation
vector_store = VectorStore()
vector_store.add_documents(chunks)

# 5. Retrieval
retriever = RAGRetriever(vector_store)
context = retriever.retrieve_context(
    query="protocole urgence vitale",
    top_k=3
)

# 6. Enrichissement LLM
prompt = f"Contexte: {context}\n\nQuestion: ..."
response = llm.generate(prompt)
```

---

##  Monitoring & MÃ©triques

### KPIs Suivis

1. **Performance**
   - Latence moyenne par composant
   - Throughput (requÃªtes/min)
   - Taux d'erreur

2. **QualitÃ©**
   - Taux de complÃ©tude conversations
   - Confiance moyenne prÃ©dictions
   - Distribution gravitÃ©s

3. **CoÃ»ts**
   - CoÃ»t total API
   - CoÃ»t par prÃ©diction
   - Tendance mensuelle

4. **Usage**
   - Nombre de sessions
   - Conversations par jour
   - PrÃ©dictions par jour

---

### Dashboards

**Monitoring.py** affiche :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KPI Cards                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Cost â”‚ â”‚ Callsâ”‚ â”‚Latencâ”‚ â”‚ Pred â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Cost Evolution (Plotly)                â”‚
â”‚  [Line Chart: Cumul cost over time]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Latency Distribution                   â”‚
â”‚  [Box Plot: By component]               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Predictions Distribution               â”‚
â”‚  [Pie Chart: By severity]               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

##  SÃ©curitÃ©

### Gestion des Secrets

**Variables Sensibles :**
```env
# .env (GIT IGNORED!)
MISTRAL_API_KEY=sk-...
OPENAI_API_KEY=sk-...  # Si utilisÃ©
```

**Chargement SÃ©curisÃ© :**
```python
from dotenv import load_dotenv
import os

load_dotenv()  # Charge .env
api_key = os.getenv("MISTRAL_API_KEY")
```

---

### Validation des EntrÃ©es

**Constantes Vitales :**
```python
VALID_RANGES = {
    "Temperature": (35.0, 42.0),
    "FC": (30, 250),
    "FR": (5, 60),
    "SpO2": (50, 100),
    "TA_systolique": (50, 250),
    "TA_diastolique": (30, 150),
}

def validate_vital(name, value):
    min_val, max_val = VALID_RANGES[name]
    if not (min_val <= value <= max_val):
        raise ValueError(f"{name} hors plage")
```

---

### Anonymisation

**DonnÃ©es Patients :**
```python
# Pas de stockage de vraies donnÃ©es mÃ©dicales
# Seulement donnÃ©es synthÃ©tiques pour ML

# Si donnÃ©es rÃ©elles â†’ anonymisation requise
patient.id = hash(patient.nom + patient.prenom)
patient.nom = None
patient.prenom = None
```

---

##  Performance

### Optimisations ImplÃ©mentÃ©es

1. **Caching LLM**
   ```python
   @lru_cache(maxsize=128)
   def get_llm_response(prompt_hash):
       # Cache rÃ©ponses identiques
   ```

2. **Batch Embeddings**
   ```python
   # Au lieu de 1 par 1
   embeddings = model.encode(texts, batch_size=32)
   ```

3. **Lazy Loading**
   ```python
   # Charger modÃ¨les seulement si nÃ©cessaire
   if self.use_ml:
       self.model = load_model()
   ```

4. **Index OptimisÃ© (ChromaDB)**
   ```python
   # HNSW index pour similaritÃ© rapide
   # O(log n) au lieu de O(n)
   ```

---

### Benchmarks

**Configuration Test :**
- CPU: Intel i7-11th Gen
- RAM: 16 GB
- Python: 3.11
- OS: Ubuntu 22.04

**RÃ©sultats :**

| OpÃ©ration | Temps Moyen | Ã‰cart-Type |
|-----------|-------------|------------|
| Chat Message | 1.2s | Â±0.3s |
| ML Prediction | 0.05s | Â±0.01s |
| RAG Retrieval | 0.3s | Â±0.1s |
| Full Workflow | 1.8s | Â±0.4s |

---

##  Configuration AvancÃ©e

### Variables d'Environnement

```env
# API Keys
MISTRAL_API_KEY=sk-...
OPENAI_API_KEY=sk-...  # Optionnel

# Paths
CHROMA_PERSIST_DIR=data/vector_db
MONITORING_DATA_DIR=app/data/monitoring

# ML
ML_MODEL_PATH=src/models/random_forest_simple.pkl
ML_CONFIDENCE_THRESHOLD=0.6

# RAG
RAG_TOP_K=3
RAG_CHUNK_SIZE=800
RAG_CHUNK_OVERLAP=150
EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/app.log

# Performance
CACHE_SIZE=128
BATCH_SIZE=32
```

---

##  RÃ©fÃ©rences

### Technologies UtilisÃ©es

- **Streamlit** : https://streamlit.io
- **Mistral AI** : https://mistral.ai
- **ChromaDB** : https://www.trychroma.com
- **scikit-learn** : https://scikit-learn.org
- **Sentence Transformers** : https://www.sbert.net
- **Plotly** : https://plotly.com

---

<div align="center">

** Documentation Technique v2.0**

*Mis Ã  jour le 02/02/2026*

**[â¬† Retour en haut](#ï¸-architecture-technique---systÃ¨me-de-triage-ia)**

</div>
